# 实时语音识别连续模式<a name="sis_03_0027"></a>

## 功能介绍<a name="zh-cn_topic_0145253500_section17636657"></a>

连续识别模式的语音总长度限制为五小时，适合于会议、演讲和直播等场景。

连续识别模式在流式识别的基础上，结合了语音的端点检测功能。语音数据也是分段输入，但是连续识别模式将会在处理数据之前进行端点检测，如果是语音才会进行实际的解码工作，如果检测到静音，将直接丢弃。如果检测到一段语音的结束点，就会直接将当前这一段的识别结果返回，然后继续检测后面的语音数据。因此在连续识别模式中，可能多次返回识别结果。如果送入的一段语音较长，甚至有可能在一次返回中包括了多段的识别结果。

由于引入了静音检测，连续识别模式通常会比流式识别能具有更高的效率，因为对于静音段将不会进行特征提取和解码操作，因而能更有效地利用CPU。而流式识别通常和客户端的端点检测功能相结合，只将检测到的有效语音段上传到服务器进行识别。

## wss-URI<a name="zh-cn_topic_0145253500_section24512189"></a>

-   wss-URI格式

    wss /v1/\{project\_id\}/rasr/continue-stream


-   参数说明

    **表 1**  参数说明

    <a name="zh-cn_topic_0145253500_table60557318"></a>
    <table><thead align="left"><tr id="zh-cn_topic_0145253500_row38729025"><th class="cellrowborder" valign="top" width="26.982698269826983%" id="mcps1.2.4.1.1"><p id="zh-cn_topic_0145253500_p50043331"><a name="zh-cn_topic_0145253500_p50043331"></a><a name="zh-cn_topic_0145253500_p50043331"></a>参数名</p>
    </th>
    <th class="cellrowborder" valign="top" width="16.53165316531653%" id="mcps1.2.4.1.2"><p id="zh-cn_topic_0145253500_p26978034"><a name="zh-cn_topic_0145253500_p26978034"></a><a name="zh-cn_topic_0145253500_p26978034"></a>是否必选</p>
    </th>
    <th class="cellrowborder" valign="top" width="56.48564856485648%" id="mcps1.2.4.1.3"><p id="zh-cn_topic_0145253500_p37737141"><a name="zh-cn_topic_0145253500_p37737141"></a><a name="zh-cn_topic_0145253500_p37737141"></a>说明</p>
    </th>
    </tr>
    </thead>
    <tbody><tr id="zh-cn_topic_0145253500_row43751799"><td class="cellrowborder" valign="top" width="26.982698269826983%" headers="mcps1.2.4.1.1 "><p id="zh-cn_topic_0145253500_p54234863"><a name="zh-cn_topic_0145253500_p54234863"></a><a name="zh-cn_topic_0145253500_p54234863"></a>project_id</p>
    </td>
    <td class="cellrowborder" valign="top" width="16.53165316531653%" headers="mcps1.2.4.1.2 "><p id="zh-cn_topic_0145253500_p30947767"><a name="zh-cn_topic_0145253500_p30947767"></a><a name="zh-cn_topic_0145253500_p30947767"></a>是</p>
    </td>
    <td class="cellrowborder" valign="top" width="56.48564856485648%" headers="mcps1.2.4.1.3 "><p id="zh-cn_topic_0145253487_p7748077"><a name="zh-cn_topic_0145253487_p7748077"></a><a name="zh-cn_topic_0145253487_p7748077"></a>项目编号。获取方法，请参见<a href="获取项目ID.md">获取项目ID</a>。</p>
    </td>
    </tr>
    </tbody>
    </table>

-   请求示例（伪码）

    ```
    wss://{endpoint}/v1/{project_id}/rasr/continue-stream
    
    Request Header:
    X-Auth-Token: MIINRwYJKoZIhvcNAQcCoIINODCCDTQCAQExDTALBglghkgBZQMEAgEwgguVBgkqhkiG...
    ```

    >![](public_sys-resources/icon-note.gif) **说明：** 
    >“endpoint“即调用API的请求地址，不同服务不同区域的“endpoint“不同，具体请参见[终端节点](终端节点.md)。

-   Python3语言请求代码示例

    ```
    # -*- coding: utf-8 -*-
    # 此demo仅供测试使用，强烈建议使用sdk。需提前安装websocket-client, 执行pip install websocket-client
    import websocket
    import threading
    import time
    import json
    
    def rasr_demo():
        url = 'wss://{{endpoint}}/v1/{{project_id}}/rasr/continue-stream'  # endpoint和project_id需替换
        audio_path = '音频路径'
        token = '用户对应region的token'
        header = {
            'X-Auth-Token': token
        }
        with open(audio_path, 'rb') as f:
            data = f.read()
        body = {
            'command': 'START',
            'config': {
                'audio_format': 'pcm8k16bit',
                'property': 'chinese_8k_common'
            }
        }
        def _on_message(ws, message):
            print(message)
        def _on_error(ws, error):
            print(error)
        ws = websocket.WebSocketApp(url, header, on_message=_on_message, on_error=_on_error)
        _thread = threading.Thread(target=ws.run_forever, args=(None, None, 30, 20))
        _thread.start()
        time.sleep(1)
        ws.send(json.dumps(body), opcode=websocket.ABNF.OPCODE_TEXT)
        now_index = 0
        byte_len = 4000
        while now_index < len(data):
            next_index = now_index + byte_len
            if next_index > len(data):
                next_index = len(data)
            send_array = data[now_index: next_index]
            ws.send(send_array, opcode=websocket.ABNF.OPCODE_BINARY)
            now_index += byte_len
            time.sleep(0.05)
        ws.send("{\"command\": \"END\", \"cancel\": \"false\"}", opcode=websocket.ABNF.OPCODE_TEXT)
        time.sleep(10)
        ws.close()
    if __name__ == '__main__':
        rasr_demo()
    ```

-   Java语言请求代码示例

    ```
    import okhttp3.OkHttpClient;
    import okhttp3.Request;
    import okhttp3.Response;
    import okhttp3.WebSocket;
    import okhttp3.WebSocketListener;
    import okio.ByteString;
    import java.net.URL;
    
    /**
     * 此demo仅供测试使用，强烈建议使用SDK
     * 使用前需已配置okhttp、okio jar包。jar包可通过下载SDK获取。
     */
    public class RasrDemo {
      public void rasrDemo() {
        try {
          // endpoint和projectId需要替换成实际信息。
          String url = "wss://{{endpoint}}/v1/{{project_id}}/asr/continue-stream";
          String token = "对应region的token";
          byte[] data = null;  // 存放将要发送音频的byte数组
          OkHttpClient okHttpClient = new OkHttpClient();
          Request request = new Request.Builder().url(url).header("X-Auth-Token", token).build();
          WebSocket webSocket = okHttpClient.newWebSocket(request, new MyListener());
          webSocket.send("{\"command\": \"START\", \"config\": {\"audio_format\": \"pcm8k16bit\", \"property\": \"chinese_8k_common\"}}");
          webSocket.send(ByteString.of(data));
          webSocket.send("{  \"command\": \"END\",  \"cancel\": false}");
          Thread.sleep(10000);
          webSocket.close(1000, null);
        } catch (Exception e) {
          e.printStackTrace();
        }
      }
      class MyListener extends WebSocketListener {
        @Override
        public void onOpen(WebSocket webSocket, Response response) {
          System.out.println("conneected");
        }
        @Override
        public void onClosed(WebSocket webSocket, int code, String reason) {
          System.out.println("closed");
        }
        @Override
        public void onFailure(WebSocket webSocket, Throwable t, Response response) {
          t.printStackTrace();
        }
        @Override
        public void onMessage(WebSocket webSocket, String text) {
          System.out.println(text);
        }
    
      }
      public static void main(String[] args) {
        RasrDemo rasrDemo = new RasrDemo();
        rasrDemo.rasrDemo();
      }
    }
    ```


